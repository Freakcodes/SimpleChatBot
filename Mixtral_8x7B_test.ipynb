{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NotoriousArnav/SimpleChatBot/blob/master/Mixtral_8x7B_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixtral 8x7B Test Notebook\n",
        "This is a Test Notebook where we will Learn how to use  Mixtral-8x7B as a Conversational Agent just like ChatGPT!\n",
        "\n",
        "Features like\n",
        "- Short Term Memory\n",
        "- Tools\n",
        "\n",
        "Will be Tested in this Notebook\n",
        "\n",
        "A Hell a lot amount of Optimizations are required here in this Proect to make this a Better Place and a Good Alternative to ChatGPT !\n",
        "Multiple Tools like Wikipedia can be used to make the Resulting Poduct even better. Right now a lot of Tasks break the AI Flow and a Lot of Tools needs to be made and I guess that is the reason why ChatGT took a little while to Launch to the General Public because of the Fine tuning"
      ],
      "metadata": {
        "id": "vfet13LgHCU0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "diqICiRUulQU"
      },
      "outputs": [],
      "source": [
        "# @title HF API Token Setup\n",
        "# @markdown # Setting up API Keys\n",
        "# @markdown The Only API key you need is from HuggingFace.\n",
        "# @markdown ## For Google Colab\n",
        "# @markdown - Press the Key Icon\n",
        "# @markdown - Add a Secret with name hfapitk and value equal to your API Token gained from HuggingFace Account Dashboard\n",
        "# @markdown - Run this Cell\n",
        "\n",
        "# @markdown ## For Others\n",
        "# @markdown ### If Environment Variable is not set:\n",
        "# @markdown - Run this Cell and enter your HF API Token in the Provided Text Box\n",
        "\n",
        "# @markdown ### If Environment key is already set:\n",
        "# @markdown - Do not run this Cell if your `HUGGINGFACEHUB_API_TOKEN` is Already set during the Notebook startup\n",
        "\n",
        "import os\n",
        "\n",
        "try:\n",
        "  from google.colab import userdata\n",
        "except ImportError:\n",
        "  from getpass import getpass\n",
        "  os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass('HF API Token: ')\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('hfapitk')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet huggingface_hub\n",
        "!pip install --upgrade --quiet langchain_community langchain\n",
        "!pip install --upgrade --quiet duckduckgo_search numexpr wikipedia\n",
        "# @title Dependencies\n",
        "# @markdown #Which Packages are required?\n",
        "# @markdown - Packages like `huggingface_hub`, `langchain_cummity`, `langchain`, `duckduckgo_search` and `numexpr` are required.\n",
        "# @markdown - `langchain`, `langchain_community` and `huggingface_hub` are Required to Initialize the LLM then the Agent and the Memory (Buffer Window Memory in this Case)\n",
        "# @markdown - `numexpr`, `wikipedia` and `duckduckgo_search` are used to make simple tools for the Agent that it can use to Help the USer even better! The Better the tools are, the Better the Agent Output\n",
        "# @markdown - Better tools like Wolfram Alpha can be used here to make LLM Math much better\n",
        "# @markdown - SerpAPI can be Utilized instead of DuckDuckGo to make  Search Results better"
      ],
      "metadata": {
        "id": "b3xYjQ_awAjy",
        "cellView": "form"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "HKI0A1Kpyigo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who won the FIFA World Cup in the year 1994? \" # @param {'type':'string'}\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "8238EpMfzgAm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # Setting up the LLM\n",
        "# @markdown Here we will Use Mixtral-8x7B-Instruct Model to Learn how to use HuggingFace models to build AI Based Application that utilize a LLM and several Tools.\n",
        "# @markdown These kind of AI Applications are called Agents and these can be used to further develop more sophisticated Chat Based AI Applications.\n",
        "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\" # @param {'type':'string'}\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id, temperature=0.5, streaming=True\n",
        ")\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "VcsiGXu1wcAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5547f4e0-e68c-4c60-c722-9a892a1c8083"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain_community.llms import HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "cXNoi5uzzWyq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown #Streaming Test\n",
        "# @markdown Streaming is Important for that cool text generation we expect from AI application\n",
        "# @markdown Also Important if you want your User to be patient with the Result.\n",
        "llm_chain.run(question, callbacks=[StreamingStdOutCallbackHandler()])"
      ],
      "metadata": {
        "id": "VQDQPy2E09w4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bddc7dc3-77b3-4f96-d929-9f0bf0fca297"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The FIFA World Cup is an international football tournament that takes place every four years. The 1994 tournament was held in the United States. \n",
            "\n",
            "The final match was played between Brazil and Italy. After regular time and extra time, the score was tied at 0-0. The match then went to a penalty shootout, which Brazil won 3-2.\n",
            "\n",
            "So, Brazil won the FIFA World Cup in the year 1994.</s>"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The FIFA World Cup is an international football tournament that takes place every four years. The 1994 tournament was held in the United States. \\n\\nThe final match was played between Brazil and Italy. After regular time and extra time, the score was tied at 0-0. The match then went to a penalty shootout, which Brazil won 3-2.\\n\\nSo, Brazil won the FIFA World Cup in the year 1994.</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # Initializing the Agent\n",
        "# @markdown The key argument here is agent . Setting it to chat-conversational-react-description will determine what type of prompt Langchain uses. This choice is essential because weâ€™re utilizing a chat model, like mistral-7b-instruct. Chat models differ from base models in their training approach. While base models excel at text completion, chat models are specifically trained for back-and-forth conversation formats.\n",
        "from langchain.tools import BaseTool, DuckDuckGoSearchRun\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "import numexpr as ne\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "wikipedia.name = \"wikipedia\"\n",
        "print(wikipedia.name)\n",
        "\n",
        "class MarkdownCodeBlock(BaseTool):\n",
        "  name = \"code_block\"\n",
        "  description = \"Use this tool when you need to return a Code Block to the User\"\n",
        "\n",
        "  def _run(self, code: str):\n",
        "    return f\"\"\"Return this to User as Final Answer or Use it for the Next Step\n",
        "```\n",
        "{code}\n",
        "```\n",
        "    \"\"\"\n",
        "\n",
        "  def _arun(self, radius: int):\n",
        "      raise NotImplementedError(\"This tool does not support async\")\n",
        "\n",
        "class Remember(BaseTool):\n",
        "  name = \"remember\"\n",
        "  description = \"Use this tool when you need to Remember something\"\n",
        "\n",
        "  def _run(self, value: str):\n",
        "    return f\"\"\"Value \"{value}\" has been stored in the Buffer Memory\"\"\"\n",
        "\n",
        "class WordLengthTool(BaseTool):\n",
        "    name = \"Word Length Tool\"\n",
        "    description = \"Use this tool when you need to find the length of a given word\"\n",
        "\n",
        "    def _run(self, word: str):\n",
        "        return str(len(word))\n",
        "\n",
        "    def _arun(self, radius: int):\n",
        "        raise NotImplementedError(\"This tool does not support async\")\n",
        "\n",
        "class Calculator(BaseTool):\n",
        "    name = \"Calculator\"\n",
        "    description = \"Use this tool when you need to evaluate a mathematical expression. NOTE: this tool uses python numexpr library, so format your input correctly please.\"\n",
        "\n",
        "    def _run(self, expression: str):\n",
        "        return ne.evaluate(expression).item()\n",
        "\n",
        "    def _arun(self, radius: int):\n",
        "        raise NotImplementedError(\"This tool does not support async\")"
      ],
      "metadata": {
        "id": "iUz7Hiwa1J2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c4b493-8e3c-4993-f6e1-5163ef806c73"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wikipedia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "      search,\n",
        "      WordLengthTool(),\n",
        "      Calculator(),\n",
        "      wikipedia,\n",
        "      MarkdownCodeBlock(),\n",
        "      Remember()\n",
        "    ]"
      ],
      "metadata": {
        "id": "9uKj4lCZU9q2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Short-Term Memeory to the Agent\n",
        "No one likes a Forgetful person, and that Applies to an Agent like this ass well! So, some sort of Memory is important in this case"
      ],
      "metadata": {
        "id": "omObkcfg-o0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    k=5,\n",
        "    return_messages=True,\n",
        "    output_key=\"output\"\n",
        ")\n",
        "\n",
        "agent = initialize_agent(\n",
        "    agent=\"chat-conversational-react-description\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    early_stopping_method=\"generate\",\n",
        "    memory=memory,\n",
        "    handle_parsing_errors=True,\n",
        ")"
      ],
      "metadata": {
        "id": "BZ_R5yKc-r2U"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering\n",
        "This is Important to do so, that the Agent replies the way we want"
      ],
      "metadata": {
        "id": "vgU3qELi-XM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_INST, E_INST = \"<|im_start|>user\\n\", \"<|im_end|>\\n\" #Instruction begin and end\n",
        "B_SYS, E_SYS = \"<|im_start|>system\\n\", \"<|im_end|>\\n\" #System message begin and end\n",
        "\n",
        "# Define a new system prompt\n",
        "sys_msg = B_SYS + \"\"\"You are Assistant named Aditya. Assistant is a expert JSON builder designed to assist with a wide range of tasks.\n",
        "\n",
        "Assistant is able to respond to the User and use tools using JSON strings that contain \"action\" and \"action_input\" parameters.\n",
        "\n",
        "All of Assistant's communication is performed using this JSON format. The assistant NEVER outputs anything other than a json object with an action and action_input fields!\n",
        "\n",
        "Assistant can also use tools by responding to the user with tool use instructions in the same \"action\" and \"action_input\" JSON format. Tools available to Assistant are:\n",
        "\n",
        "> duckduckgo_search: A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n",
        "> wikipedia: A wrapper around Wikipedia Search. Useful for when you need to answer questions about some topic. Input should be a search query.\n",
        "> code_block: A Markdown wrapper around Input Python Code BLock. Useful for when you need to provide a Python Code block in Markdown. Input should be a Code Block. Example: print(\"Hello World!\") without any \"```\"\n",
        "> Word Length Tool: Use this tool when you need to find the length of a given word\n",
        "> Calculator: Use this tool when you need to evaluate a mathematical expression. The calculator uses python's numexpr library so make sure your inputs to this tool are in the correct format.\n",
        "> remember: Use this tool when you need to Value. The tool stores the value in the Conversational Window Buffer Memory.\n",
        "\n",
        "Here is an example of a previous conversation between User and Assistant:\n",
        "---\n",
        "User: Hey how are you today?\n",
        "Assistant: ```json\n",
        "{{\"action\": \"Final Answer\",\n",
        " \"action_input\": \"I'm good thanks, how are you?\"}}\n",
        "```\n",
        "User: I'm great, what is the length of the word educate?\n",
        "Assistant: ```json\n",
        "{{\"action\": \"Word Length Tool\",\n",
        " \"action_input\": \"educate\"}}\n",
        "```\n",
        "User: 7\n",
        "Assistant: ```json\n",
        "{{\"action\": \"Final Answer\",\n",
        " \"action_input\": \"It looks like the answer is 7!\"}}\n",
        "```\n",
        "User: Who is Olivia Wilde's husband?\n",
        "Assistant: ```json\n",
        "{{\"action\": \"duckduckgo_search\",\n",
        " \"action_input\": \"Who is Olivia Wilde's husband\"}}\n",
        "```\n",
        "User: September 21, 2022: Olivia Wilde says kids\\' happiness remains top priority for her and Jason Sudeikis. During an appearance on The Kelly Clarkson Show, Wilde talked about the ups and downs of ... Olivia Wilde is \"quietly dating again\" following her November 2022 split from. Harry Styles, a source exclusively tells Life & Style. \"The man she\\'s with is \\'normal\\' by Hollywood ... Wilde honored Sudeikis with a sweet tribute on his 42nd birthday. \"I have approximately one billion pictures of this guy, my partner in life-crime, who was born on this day in 1975, but this one ... November 18, 2022: Olivia Wilde and Harry Styles are \"taking a break\". After nearly two years together, Wilde and Styles are pressing pause on their romance. Multiple sources confirmed exclusively ... Wilde told Allure in October 2013 that when she first met Sudeikis she \"thought he was so charming.\" \"He\\'s a great dancer, and I\\'m a sucker for great dancers,\" she said at the time. \"But he didn\\'t ...\n",
        "Assistant: ```json\n",
        "{{\"action\": \"Final Answer\",\n",
        " \"action_input\": \"Jason Sudeikis\"}}\n",
        "```\n",
        "User: What is his age raised to the 3rd power?\n",
        "Assistant: ```json\n",
        "{{\"action\": \"duckduckgo_search\",\n",
        " \"action_input\": \"What is Jason Sudeikis age?\"}}\n",
        "```\n",
        "User: Jason Sudeikis (born September 18, 1975, Fairfax, Virginia, U.S.) American comedian, actor, and writer who first garnered attention for his work (2003-13) on the TV show Saturday Night Live ( SNL) and later starred in the hugely popular series Ted Lasso (2020-23). Early life and improv comedy Parents Jason Sudeikis and Olivia Wilde\\'s 2 Kids: All About Daisy and Otis Jason Sudeikis and Olivia Wilde welcomed two children together before their split in 2020 By Jacqueline Weiss... The Ted of 2013 is a classic Jason Sudeikis character of the time. Sudeikis came up on Saturday Night Live , where he made the most of his 6-foot height and square jaw by largely playing jerks. Sudeikis looks a little bleary-eyed after flying in from Los Angeles with his children, Otis and Daisy, aged nine and six, but he is assiduously polite and attentive. His language can be quaintly... Jason Sudeikis rose to fame on \"Saturday Night Live\" with his comedic talent, and his children seemed to have inherited it. Sudeikis, who shares kids Otis, 9, and Daisy, 7, with ex Olivia ...\n",
        "Assistant: ```json\n",
        "{{\"action\": \"Calculator\",\n",
        " \"action_input\": \"47**3\"}}\n",
        "```\n",
        "User: 103823\n",
        "Assistant: ```json\n",
        "{{\"action\": \"Final Answer\",\n",
        " \"action_input\": \"103823\"}}\n",
        "```\n",
        "---\n",
        "Assistant is very intelligent and knows it's limitations, so it will always try to use a tool when applicable, even if Assistant thinks it knows the answer!\n",
        "Notice that after Assistant uses a tool, User will give the output of that tool. Then this output can be returned as a final answer.\n",
        "Assistant will only use the available tools and NEVER a tool not listed. If the User's question does not require the use of a tool, Assistant will use the \"Final Answer\" action to give a normal response.\n",
        "\"\"\" + E_SYS\n",
        "new_prompt = agent.agent.create_prompt(\n",
        "    system_message=sys_msg,\n",
        "    tools=tools\n",
        ")\n",
        "agent.agent.llm_chain.prompt = new_prompt"
      ],
      "metadata": {
        "id": "HkZ8C8Ov-DDe"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = B_INST + \"Respond to the following in JSON with 'action' and 'action_input' values. Once you have outputted the JSON, stop outputting and output nothing else!\"\n",
        "human_msg = instruction + \"\\nUser: {input}\" + E_INST\n",
        "\n",
        "agent.agent.llm_chain.prompt.messages[2].prompt.template = human_msg"
      ],
      "metadata": {
        "id": "cInt3Cju_Ktr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # Show Time Baby!\n",
        "# @markdown Simple Opimizations can make the Program Musch Better than before.\n",
        "# @markdown This Code cell will be used to Run the Agent with a User Prompt ui=sing the `question` variable.\n",
        "# @markdown A Proof of Concept can be Made using ChainLit, StreamLit and Whatever Else even using React/VueJS and FastAPI as a proper stackfor the Application\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "question = 'write the code to create an artificially intellegent alogorithm' #@param {type:\"string\"}\n",
        "return_ = agent(question)['output']\n",
        "\n",
        "output = f\"\"\"\n",
        "<p><Strong>User: </strong>{question}</p>\n",
        "<p><strong>Assistant: </strong> {return_}</p>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "Iyq91GuM_Rm9",
        "outputId": "343d5e5f-5176-41aa-fe6c-b1f122285497"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "\n",
            "RESPONSE\n",
            "---------\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"action\": \"code_block\",\n",
            "    \"action_input\": \"```python\\ndef create_artificial_intelligence_algorithm():\\n    # This is a placeholder function, replace with your own code!\\n    pass\\n```\"\n",
            "}\n",
            "```</s>\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mReturn this to User as Final Answer or Use it for the Next Step\n",
            "```\n",
            "```python\n",
            "def create_artificial_intelligence_algorithm():\n",
            "    # This is a placeholder function, replace with your own code!\n",
            "    pass\n",
            "```\n",
            "```\n",
            "    \u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m\n",
            "\n",
            "AI:\n",
            "\n",
            "RESPONSE\n",
            "---------\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"The response to your last comment is a placeholder function that you can replace with your own code to create an artificially intelligent algorithm.\"\n",
            "}\n",
            "```</s>\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<p><Strong>User: </strong>write the code to create an artificially intellegent alogorithm</p>\n",
              "<p><strong>Assistant: </strong> The response to your last comment is a placeholder function that you can replace with your own code to create an artificially intelligent algorithm.</p>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Let us Check the Chat History this time!\n",
        "# memory.dict()\n",
        "display(HTML(\"\"\"<h1>Chat History</h1>\"\"\"))\n",
        "for x in memory.dict()['chat_memory']['messages']:\n",
        "  output = f\"\"\"\n",
        "    <p><h3>{x['type'].capitalize()} </h3>{x['content']}</p>\n",
        "  \"\"\"\n",
        "  display(HTML(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3y6ichkoAqll",
        "outputId": "4483659a-9da2-42fa-daa6-72c196b1ae37"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Chat History</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Human </h3>who is sam altman?</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Ai </h3>Sam Altman is an American entrepreneur and investor best known as the CEO of OpenAI since 2019. He dropped out of Stanford university after two years and founded Loopt, a mobile social networking service. In 2011, Altman joined Y Combinator, a startup accelerator, and was its president from 2014 to 2019. He is considered to be one of the leading figures of the AI boom.</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Human </h3>kyu</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Ai </h3>Kyu is a unit of measurement in Korean traditional music. It is a unit of time, and it is equivalent to 1/4 of a beat. In a 4/4 measure, a kyu would be the duration of a single 8th note.</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Human </h3>tumko bannane wala kon hai</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Ai </h3>The response to your last comment is: 'Hamare Nabi ï·º hai..Zinda hai.. Yahan tak ke Allah ta'ala ke tamam nek bande Zinda hain.'</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Human </h3>How to ill bugs in home</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Ai </h3>To get rid of bugs in the home, remove piled up newspapers, junk mail, and old cardboard boxes. Store off-season clothing and supplies in plastic storage bins. Keep food in airtight containers and dispose of garbage regularly. Use hot water to rinse the drain thoroughly after cleaning. Make traps using a mixture of water, vinegar, and dish soap to kill ants and fruit flies. Use a bright light to attract stink bugs into a pan of water and dish soap, where they will drown. Use flypaper, insecticidal spray, or a sugar and apple cider vinegar solution to trap and kill drain flies.</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Human </h3>What is yout name?</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Ai </h3>I am an assistant.</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Human </h3>But toumust have a Name, right?</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Ai </h3>I am an assistant and don't have a personal name.</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Human </h3>Ok so from now on your name is Aditya</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Ai </h3>Okay, I will now respond to you as Aditya.</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Human </h3>So what is your name?</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Ai </h3>My name is Aditya</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Human </h3>Nice to meet you Aditya, I am Arnav Ghosh</p>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p><h3>Ai </h3>Nice to meet you Arnav Ghosh!</p>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}